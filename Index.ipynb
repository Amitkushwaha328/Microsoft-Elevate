{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1124bcfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded Successfully!\n",
      "Total Complaints: 1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complaint_id</th>\n",
       "      <th>complaint_text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>area</th>\n",
       "      <th>issue_category</th>\n",
       "      <th>issue_type</th>\n",
       "      <th>severity_level</th>\n",
       "      <th>complaint_channel</th>\n",
       "      <th>user_repeat_flag</th>\n",
       "      <th>affected_duration_hours</th>\n",
       "      <th>resolution_status</th>\n",
       "      <th>priority_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Too many potholes near the main junction.</td>\n",
       "      <td>2026-02-08 10:15:00</td>\n",
       "      <td>Ahmedabad West</td>\n",
       "      <td>road</td>\n",
       "      <td>pothole</td>\n",
       "      <td>high</td>\n",
       "      <td>app</td>\n",
       "      <td>no</td>\n",
       "      <td>12</td>\n",
       "      <td>open</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Garbage truck did not come since 3 days.</td>\n",
       "      <td>2026-02-08 11:20:00</td>\n",
       "      <td>Ahmedabad East</td>\n",
       "      <td>garbage</td>\n",
       "      <td>garbage_not_collected</td>\n",
       "      <td>medium</td>\n",
       "      <td>web</td>\n",
       "      <td>yes</td>\n",
       "      <td>72</td>\n",
       "      <td>in_progress</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Dirty water coming from tap.</td>\n",
       "      <td>2026-02-08 06:45:00</td>\n",
       "      <td>Ahmedabad North</td>\n",
       "      <td>water</td>\n",
       "      <td>dirty_water</td>\n",
       "      <td>high</td>\n",
       "      <td>call</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>open</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   complaint_id                             complaint_text  \\\n",
       "0             1  Too many potholes near the main junction.   \n",
       "1             2   Garbage truck did not come since 3 days.   \n",
       "2             3               Dirty water coming from tap.   \n",
       "\n",
       "            timestamp             area issue_category             issue_type  \\\n",
       "0 2026-02-08 10:15:00   Ahmedabad West           road                pothole   \n",
       "1 2026-02-08 11:20:00   Ahmedabad East        garbage  garbage_not_collected   \n",
       "2 2026-02-08 06:45:00  Ahmedabad North          water            dirty_water   \n",
       "\n",
       "  severity_level complaint_channel user_repeat_flag  affected_duration_hours  \\\n",
       "0           high               app               no                       12   \n",
       "1         medium               web              yes                       72   \n",
       "2           high              call               no                        2   \n",
       "\n",
       "  resolution_status priority_label  \n",
       "0              open           high  \n",
       "1       in_progress         medium  \n",
       "2              open           high  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Load the Dataset (Make sure the file is in the same folder)\n",
    "df = pd.read_csv(\"complaints_master.csv\")\n",
    "\n",
    "# Convert Timestamp to DateTime object immediately\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "print(\"Data Loaded Successfully!\")\n",
    "print(f\"Total Complaints: {df.shape[0]}\")\n",
    "display(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4832f74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Cleaning Complete. Example:\n",
      "complaint_text    Too many potholes near the main junction.\n",
      "cleaned_text       too many potholes near the main junction\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)  # Remove text in brackets\n",
    "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text) # Remove punctuation\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text) # Remove words containing numbers\n",
    "    return text\n",
    "\n",
    "# Apply cleaning\n",
    "df['cleaned_text'] = df['complaint_text'].apply(clean_text)\n",
    "\n",
    "print(\"Text Cleaning Complete. Example:\")\n",
    "print(df[['complaint_text', 'cleaned_text']].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e6dd6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy Score: 0.985\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    drainage       1.00      1.00      1.00        17\n",
      " electricity       1.00      0.95      0.98        22\n",
      "     garbage       0.98      1.00      0.99        40\n",
      "        road       0.97      0.97      0.97        30\n",
      "street_light       0.96      1.00      0.98        27\n",
      "     traffic       1.00      1.00      1.00        27\n",
      "       water       1.00      0.97      0.99        37\n",
      "\n",
      "    accuracy                           0.98       200\n",
      "   macro avg       0.99      0.98      0.99       200\n",
      "weighted avg       0.99      0.98      0.98       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Convert Text to Numbers (TF-IDF)\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf.fit_transform(df['cleaned_text'])\n",
    "y = df['issue_category']  # This is our target (what we want to predict)\n",
    "\n",
    "# 2. Split Data (80% for training, 20% for testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Train Model (Logistic Regression is great for text)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 4. Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Model Accuracy Score:\", model.score(X_test, y_test))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8202b308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0: 'garbage' 'since' 'no' 'supply' 'water' 'society' \n",
      "Cluster 1: 'water' 'in' 'society' 'block' 'power' 'is' \n",
      "Cluster 2: 'light' 'pole' 'is' 'signal' 'street' 'broken' \n",
      "Cluster 3: 'road' 'near' 'on' 'main' 'the' 'blocked' \n",
      "Cluster 4: 'tonight' 'morning' 'today' 'area' 'side' 'exit' \n"
     ]
    }
   ],
   "source": [
    "# We use K-Means to find 5 main clusters of issues\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Assign the cluster label to the original dataframe\n",
    "df['cluster_label'] = kmeans.labels_\n",
    "\n",
    "# Show what each cluster looks like (Top terms)\n",
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = kmeans.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = tfidf.get_feature_names_out()\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"Cluster {i}: \", end=\"\")\n",
    "    for ind in order_centroids[i, :6]: # Top 6 words per cluster\n",
    "        print(f\"'{terms[ind]}' \", end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd5d37d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spike Detection Analysis:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>area</th>\n",
       "      <th>complaint_count</th>\n",
       "      <th>is_spike</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2026-02-08</td>\n",
       "      <td>5</td>\n",
       "      <td>Ahmedabad South</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2026-02-08</td>\n",
       "      <td>5</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2026-02-08</td>\n",
       "      <td>6</td>\n",
       "      <td>Ahmedabad North</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2026-02-08</td>\n",
       "      <td>6</td>\n",
       "      <td>Ahmedabad South</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2026-02-08</td>\n",
       "      <td>6</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>25</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2026-02-08</td>\n",
       "      <td>21</td>\n",
       "      <td>Ahmedabad South</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>2026-02-08</td>\n",
       "      <td>21</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>2026-02-08</td>\n",
       "      <td>21</td>\n",
       "      <td>Pune</td>\n",
       "      <td>18</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2026-02-08</td>\n",
       "      <td>22</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2026-02-08</td>\n",
       "      <td>22</td>\n",
       "      <td>Pune</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  hour             area  complaint_count  is_spike\n",
       "1    2026-02-08     5  Ahmedabad South                6      True\n",
       "2    2026-02-08     5        Bangalore                9      True\n",
       "7    2026-02-08     6  Ahmedabad North                9      True\n",
       "8    2026-02-08     6  Ahmedabad South                6      True\n",
       "9    2026-02-08     6        Bangalore               25      True\n",
       "..          ...   ...              ...              ...       ...\n",
       "107  2026-02-08    21  Ahmedabad South                7      True\n",
       "110  2026-02-08    21        Hyderabad               10      True\n",
       "112  2026-02-08    21             Pune               18      True\n",
       "115  2026-02-08    22        Hyderabad                7      True\n",
       "117  2026-02-08    22             Pune               10      True\n",
       "\n",
       "[63 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract Hour from timestamp for hourly analysis\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "df['date'] = df['timestamp'].dt.date\n",
    "\n",
    "# Count complaints per Area per Hour\n",
    "spike_df = df.groupby(['date', 'hour', 'area']).size().reset_index(name='complaint_count')\n",
    "\n",
    "# Define a Threshold (e.g., if > 5 complaints in one hour in one area)\n",
    "THRESHOLD = 5\n",
    "spike_df['is_spike'] = spike_df['complaint_count'] > THRESHOLD\n",
    "\n",
    "print(\"Spike Detection Analysis:\")\n",
    "spikes = spike_df[spike_df['is_spike'] == True]\n",
    "if not spikes.empty:\n",
    "    display(spikes)\n",
    "else:\n",
    "    print(\"No massive spikes detected with current threshold.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8eafe876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Most Urgent Complaints:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complaint_id</th>\n",
       "      <th>area</th>\n",
       "      <th>issue_category</th>\n",
       "      <th>ai_priority_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>959</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>garbage</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>61</td>\n",
       "      <td>Ahmedabad East</td>\n",
       "      <td>garbage</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>376</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>garbage</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>585</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>garbage</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>375</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>garbage</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     complaint_id            area issue_category  ai_priority_score\n",
       "958           959       Hyderabad        garbage                  8\n",
       "60             61  Ahmedabad East        garbage                  8\n",
       "375           376       Bangalore        garbage                  8\n",
       "584           585       Bangalore        garbage                  8\n",
       "374           375       Bangalore        garbage                  8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Map text severity to numbers\n",
    "severity_map = {'high': 3, 'medium': 2, 'low': 1}\n",
    "df['severity_score'] = df['severity_level'].map(severity_map)\n",
    "\n",
    "# Priority Formula:\n",
    "# Score = (Severity * 2) + (1 if User Repeated else 0) + (1 if Duration > 24hrs)\n",
    "df['ai_priority_score'] = (df['severity_score'] * 2) + \\\n",
    "                          (df['user_repeat_flag'].apply(lambda x: 1 if x == 'yes' else 0)) + \\\n",
    "                          (df['affected_duration_hours'].apply(lambda x: 1 if x > 24 else 0))\n",
    "\n",
    "# Sort by Priority\n",
    "priority_queue = df.sort_values(by='ai_priority_score', ascending=False)\n",
    "\n",
    "print(\"Top 5 Most Urgent Complaints:\")\n",
    "display(priority_queue[['complaint_id', 'area', 'issue_category', 'ai_priority_score']].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "795673c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Generated Explanation for Complaint #959:\n",
      "URGENT: Hyderabad is experiencing a severe surge in garbage reports (1 total). Immediate dispatch required.\n"
     ]
    }
   ],
   "source": [
    "# This is a PLACEHOLDER function.\n",
    "# In the real project, you insert your Azure OpenAI Key here.\n",
    "\n",
    "def generate_explanation(area, issue, count, spike_status):\n",
    "    # This is the prompt we WOULD send to GPT-4\n",
    "    prompt = f\"\"\"\n",
    "    Act as a city infrastructure assistant.\n",
    "    Analyze this data:\n",
    "    - Area: {area}\n",
    "    - Issue Type: {issue}\n",
    "    - Complaint Count: {count}\n",
    "    - Is Spike?: {spike_status}\n",
    "\n",
    "    Write a 1-sentence summary for the mayor explaining the situation.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Mock response for now (Pretending AI generated this)\n",
    "    if spike_status:\n",
    "        return f\"URGENT: {area} is experiencing a severe surge in {issue} reports ({count} total). Immediate dispatch required.\"\n",
    "    else:\n",
    "        return f\"Routine maintenance required in {area} for reported {issue} issues.\"\n",
    "\n",
    "# Test the function on the top priority item\n",
    "top_issue = priority_queue.iloc[0]\n",
    "explanation = generate_explanation(\n",
    "    area=top_issue['area'], \n",
    "    issue=top_issue['issue_category'], \n",
    "    count=1, \n",
    "    spike_status=\"Yes\"\n",
    ")\n",
    "\n",
    "print(f\"AI Generated Explanation for Complaint #{top_issue['complaint_id']}:\")\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ded644c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and Vectorizer saved!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the vectorizer and the model\n",
    "with open('tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf, f)\n",
    "\n",
    "with open('complaint_classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(\"Model and Vectorizer saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96872f19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00c7c57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
